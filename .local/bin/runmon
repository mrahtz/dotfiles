#!/usr/bin/env python3

import argparse
import datetime
import fnmatch
import glob
import io
import os
import platform
import random
import shutil
import subprocess
import sys
import tempfile
import time
import uuid
from threading import Thread

import boto3
import daemon

session = boto3.Session(profile_name='runs_s3')
s3 = session.client('s3')
s3.list_objects(Bucket='mrahtz-runs-2')


def find_files_matching_pattern(pattern, path):
    result = []
    for root, dirs, files in os.walk(path, followlinks=True):
        for name in files:
            if fnmatch.fnmatch(name, pattern):
                result.append(os.path.join(root, name))
    return result


def monitor(paths):
    paths = [p for p in paths if os.path.exists(p) and os.path.isdir(p)]
    while True:
        if any([not os.path.exists(p) for p in paths]):
            break

        print("Plotting...")
        try:
            subprocess.run(['tbplot'] + paths, check=True)
        except subprocess.CalledProcessError as e:
            print(e)

        print("Zipping events files...")
        try:
            for path in paths:
                path = os.path.normpath(path)  # Strip trailing slash
                events_files = find_files_matching_pattern('events*', path)
                if not events_files:
                    continue
                with tempfile.TemporaryDirectory() as d:
                    for f in events_files:
                        target_dir = os.path.join(d, os.path.dirname(f))
                        os.makedirs(target_dir, exist_ok=True)
                        shutil.copy(f, target_dir)
                    shutil.make_archive(path, 'zip', d)
        except subprocess.CalledProcessError as e:
            print(e)

        print("Zipping videos...")
        try:
            for path in paths:
                path = os.path.normpath(path)  # Strip trailing slash
                video_files = find_files_matching_pattern('*mp4', os.path.join(path, 'test_env'))
                video_files += find_files_matching_pattern('*mp4', os.path.join(path, 'train_env'))
                if not video_files:
                    continue
                video_files = sorted(video_files, key=lambda f: os.path.getmtime(f))
                video_files = video_files[-20:-1]
                with tempfile.TemporaryDirectory() as d:
                    for f in video_files:
                        target_dir = os.path.join(d, os.path.dirname(f))
                        os.makedirs(target_dir, exist_ok=True)
                        shutil.copy(f, target_dir)
                    shutil.make_archive(path + '_videos', 'zip', d)
        except subprocess.CalledProcessError as e:
            print(e)

        print("Uploading...")
        for f in glob.glob('*.png') + glob.glob('*.zip'):
            with open(f, 'rb') as fd:
                b = fd.read()
            s3.upload_fileobj(io.BytesIO(b), 'mrahtz-runs-2', os.path.basename(f), ExtraArgs={'ACL': 'public-read'})

        print("Sleeping...")
        stagger_minutes = random.randint(1, 5)
        time.sleep((5 + stagger_minutes) * 60)


def download_file(s3, filename, last_modified, target_dir):
    target_file = os.path.join(target_dir, filename)
    print(f"Downloading {filename}...")
    s3.download_file('mrahtz-runs-2', filename, target_file)
    os.utime(target_file, (last_modified, last_modified))


def download_files_from_bucket(zips, old):
    tmp_dir = tempfile.mkdtemp()
    print("Listing bucket...")
    files = s3.list_objects(Bucket='mrahtz-runs-2')
    threads = []
    print("Downloading files...")
    for content in files['Contents']:
        filename = content['Key']
        if (not zips) and '.zip' in filename:
            continue
        last_modified = content['LastModified']
        last_modified = last_modified.replace(tzinfo=datetime.timezone.utc).timestamp()
        if old or (time.time() - last_modified < (24 * 60 * 60)):
            t = Thread(target=download_file, args=(s3, filename, last_modified, tmp_dir))
            threads.append(t)
            t.start()
    for t in threads:
        t.join()
    return tmp_dir


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--foreground', action='store_true')
    group = parser.add_mutually_exclusive_group()
    group.add_argument('--get', action='store_true')
    group.add_argument('--paths', nargs='+')
    parser.add_argument('--zips', action='store_true')
    parser.add_argument('--old', action='store_true')
    args = parser.parse_args()

    if args.get:
        tmp_dir = download_files_from_bucket(args.zips, args.old)
        if args.zips:
            for p in glob.glob(os.path.join(tmp_dir, '*.zip')):
                if time.time() - os.path.getmtime((p)) < (24 * 60 * 60):
                    print(f"Unzipping {p}...")
                    shutil.unpack_archive(p, tmp_dir)
                    os.remove(p)
        if platform.system() == 'Darwin':
            subprocess.run(['open', tmp_dir])
        else:
            print(f"Files downloaded to {tmp_dir}")
    elif args.paths:
        for p in args.paths:
            if not os.path.exists(p):
                print(f"Error: path '{p}' does not exist", file=sys.stderr)
                exit(1)
        if args.foreground:
            monitor(args.paths)
        else:
            name = str(uuid.uuid4())
            log_file = open('/tmp/runmon-' + name + '.log', 'w')
            with daemon.DaemonContext(stdout=log_file, stderr=log_file, working_directory=os.getcwd()):
                monitor(args.paths)
    else:
        parser.print_help()


if __name__ == '__main__':
    main()
